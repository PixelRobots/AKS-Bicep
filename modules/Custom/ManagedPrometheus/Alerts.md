## Kubernetes Alert RuleGroup-RecommendedCIAlerts - 0.1

| Alert | Expression | For | Description | Severity | Time to Resolve |
| --- | --- | --- | --- | --- | --- | 
| Average CPU usage per container is greater than 95% | `sum (rate(container_cpu_usage_seconds_total{image!="", container_name!="POD"}[5m])) by (pod,cluster,container,namespace) / sum(container_spec_cpu_quota{image!="", container_name!="POD"}/container_spec_cpu_period{image!="", container_name!="POD"}) by (pod,cluster,container,namespace) > .95` | PT5M | Average CPU usage per container is greater than 95% | 4 | PT15M |
| Average Memory usage per container is greater than 95% | `(container_memory_working_set_bytes{container!="", image!="", container_name!="POD"} / on(namespace,cluster,pod,container) group_left kube_pod_container_resource_limits{resource="memory", node!=""}) > .95` | PT10M | Average Memory usage per container is greater than 95% | 4 | PT10M |
| Number of OOM killed containers is greater than 0 | `sum by (cluster,container,namespace)(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}) > 0` | PT5M | Number of OOM killed containers is greater than 0 | 4 | PT10M |
| Average PV usage is greater than 80% | `sum by (namespace,cluster,container,pod)(kubelet_volume_stats_used_bytes{job="kubelet"}) / sum by (namespace,cluster,container,pod)(kubelet_volume_stats_capacity_bytes{job="kubelet"})  >.8` | PT5M | Average PV usage is greater than 80% | 4 | PT15M |
| Pod container restarted in last 1 hour | `sum by (namespace, pod, container, cluster) (kube_pod_container_status_restarts_total{job="kube-state-metrics", namespace="kube-system"}) > 0` | PT15M | Pod container restarted in last 1 hour | 4 | PT10M |
| Node is not ready. | `sum by (namespace,cluster,node)(kube_node_status_condition{job="kube-state-metrics",condition="Ready",status!="true", node!=""}) > 0` | PT15M | Node has been unready for more than 15 minutes | 4 | PT15M |
| Ready state of pods is less than 80%. | `sum by (cluster,namespace,deployment)(kube_deployment_status_replicas_ready) / sum by (cluster,namespace,deployment)(kube_deployment_spec_replicas) <.8 or sum by (cluster,namespace,deployment)(kube_daemonset_status_number_ready) / sum by (cluster,namespace,deployment)(kube_daemonset_status_desired_number_scheduled) <.8` | PT5M | Ready state of pods is less than 80%. | 4 | PT15M |
| Job did not complete in time | `sum by(namespace,cluster)(kube_job_spec_completions{job="kube-state-metrics"}) - sum by(namespace,cluster)(kube_job_status_succeeded{job="kube-state-metrics"})  > 0` | PT360M | Number of stale jobs older than six hours is greater than 0 | 4 | PT15M |
| Average node CPU utilization is greater than 80% | `(  (1 - rate(node_cpu_seconds_total{job="node", mode="idle"}[5m]) ) / ignoring(cpu) group_left count without (cpu)( node_cpu_seconds_total{job="node", mode="idle"}) ) > .8` | PT5M | Average node CPU utilization is greater than 80% | 4 | PT15M |
| Working set memory for a node is greater than 80%. | `1 - avg by (namespace,cluster,job)(node_memory_MemAvailable_bytes{job="node"}) / avg by (namespace,cluster,job)(node_memory_MemTotal_bytes{job="node"}) > .8` | PT5M | Working set memory for a node is greater than 80%. | 4 | PT15M |
| Number of pods in failed state are greater than 0. | `sum by (cluster, namespace, pod) (kube_pod_status_phase{phase="failed"}) > 0` | PT5M | Number of pods in failed state are greater than 0 | 4 | PT15M |

## Kubernetes Alert RuleGroup-communityCIAlerts - 0.1

| Alert | Expression | For | Description | Severity | Time to Resolve |
| --- | --- | --- | --- | --- | --- |
| NodeFilesystemSpaceFillingUp | `avg by (namespace,cluster,job,device,instance,mountpoint)(node_filesystem_avail_bytes{job="node",fstype!=""}) / avg by (namespace,cluster,job,device,instance,mountpoint)(node_filesystem_size_bytes{job="node",fstype!=""}) * 100 < 40 and avg by (namespace,cluster,job,device,instance,mountpoint)(predict_linear(node_filesystem_avail_bytes{job="node",fstype!=""}[6h], 24*60*60)) < 0 and avg by (namespace,cluster,job,device,instance,mountpoint)(node_filesystem_readonly{job="node",fstype!=""}) == 0` | PT15M | An extrapolation algorithm predicts that disk space usage for node {{ $labels.instance }} on device {{ $labels.device }} in {{ $labels.cluster}} will run out of space within the upcoming 24 hours. For more information on this alert, please refer to this [link](https://github.com/prometheus-operator/runbooks/blob/main/content/runbooks/node/NodeFilesystemSpaceFillingUp.md).| 3 | PT10M |
| NodeFilesystemSpaceUsageFull85Pct | `1 - avg by (namespace,cluster,job,device,instance,mountpoint)(node_filesystem_avail_bytes{job="node"}) / avg by (namespace,cluster,job,device,instance,mountpoint)(node_filesystem_size_bytes{job="node"}) > .85` | PT15M | Disk space usage for node {{ $labels.instance }} on device {{ $labels.device }} in {{ $labels.cluster}} is greater than 85%. For more information on this alert, please refer to this [link](https://github.com/prometheus-operator/runbooks/blob/main/content/runbooks/node/NodeFilesystemAlmostOutOfSpace.md).| 3 | PT10M |


## kubernetes-apps

| Alert | Expression | For | Description | Severity | Time to Resolve |
| --- | --- | --- | --- | --- | --- |
| KubePodCrashLooping | `max_over_time(kube_pod_container_status_waiting_reason{reason="CrashLoopBackOff", job="kube-state-metrics"}[5m]) >= 1` | PT15M | Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container }}) is in waiting state (reason: "CrashLoopBackOff").  | 3 | PT10M |
| KubePodNotReady | `sum by (namespace, pod, cluster) (max by(namespace, pod, cluster) (kube_pod_status_phase{job="kube-state-metrics", phase=~"Pending\|Unknown\|Failed"}) * on(namespace, pod, cluster) group_left(owner_kind) topk by(namespace, pod, cluster) (1, max by(namespace, pod, owner_kind, cluster) (kube_pod_owner{owner_kind!="Job"}))) > 0` | PT15M | Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready state for longer than 15 minutes. | 3 | PT10M |
| KubeDeploymentGenerationMismatch | `kube_deployment_status_observed_generation{job="kube-state-metrics"} != kube_deployment_metadata_generation{job="kube-state-metrics"}` | PT15M  | Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment }} does not match, this indicates that the Deployment has failed but has not been rolled back. | 3 | PT10M |
| KubeDeploymentReplicasMismatch | `(kube_deployment_spec_replicas{job="kube-state-metrics"} > kube_deployment_status_replicas_available{job="kube-state-metrics"}) and (changes(kube_deployment_status_replicas_updated{job="kube-state-metrics"}[10m]) == 0)` | PT15M  | Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not matched the expected number of replicas for longer than 15 minutes. | 3 | PT10M |
| KubeStatefulSetReplicasMismatch | `(kube_statefulset_status_replicas_ready{job="kube-state-metrics"} != kube_statefulset_status_replicas{job="kube-state-metrics"}) and (changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[10m]) == 0)` | PT15M  | StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has not matched the expected number of replicas for longer than 15 minutes. | 3 | PT10M |
| KubeStatefulSetGenerationMismatch | `kube_statefulset_status_observed_generation{job="kube-state-metrics"} != kube_statefulset_metadata_generation{job="kube-state-metrics"}` | PT15M  | StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset }} does not match, this indicates that the StatefulSet has failed but has not been rolled back. | 3 | PT10M |
| KubeStatefulSetUpdateNotRolledOut | `(\n  max without (revision) (\n    kube_statefulset_status_current_revision{job="kube-state-metrics"}\n      unless\n    kube_statefulset_status_update_revision{job="kube-state-metrics"}\n  )\n    *\n  (\n    kube_statefulset_replicas{job="kube-state-metrics"}\n      !=\n    kube_statefulset_status_replicas_updated{job="kube-state-metrics"}\n  )\n)  and (\n  changes(kube_statefulset_status_replicas_updated{job="kube-state-metrics"}[5m])\n    ==\n  0\n)` | PT15M | StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update has not been rolled out. | warning  | PT10M |
| KubeDaemonSetRolloutStuck | `(\n  (\n    kube_daemonset_status_current_number_scheduled{job="kube-state-metrics"}\n     !=\n    kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}\n  ) or (\n    kube_daemonset_status_number_misscheduled{job="kube-state-metrics"}\n     !=\n    0\n  ) or (\n    kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics"}\n     !=\n    kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}\n  ) or (\n    kube_daemonset_status_number_available{job="kube-state-metrics"}\n     !=\n    kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}\n  )\n) and (\n  changes(kube_daemonset_status_updated_number_scheduled{job="kube-state-metrics"}[5m])\n    ==\n  0\n)` | PT15M | DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} has not finished or progressed for at least 15 minutes. | warning  | PT10M |
| KubeContainerWaiting | `sum by (namespace, pod, container, cluster) (kube_pod_container_status_waiting_reason{job="kube-state-metrics"}) > 0` | PT1H | pod/{{ $labels.pod }} in namespace {{ $labels.namespace }} on container {{ $labels.container}} has been in waiting state for longer than 1 hour. | warning  | PT10M |
| KubeDaemonSetNotScheduled | `kube_daemonset_status_desired_number_scheduled{job="kube-state-metrics"}\n  -\nkube_daemonset_status_current_number_scheduled{job="kube-state-metrics"} > 0` | PT10M | {{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are not scheduled. | warning  | PT10M |
| KubeDaemonSetMisScheduled | `kube_daemonset_status_number_misscheduled{job="kube-state-metrics"} > 0` | PT15M | {{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset }} are running where they are not supposed to run. | warning  | PT10M |
| KubeJobNotCompleted | `time() - max by(namespace, job_name, cluster) (kube_job_status_start_time{job="kube-state-metrics"}\n  and\nkube_job_status_active{job="kube-state-metrics"} > 0) > 43200` |       | Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more than 12 hours to complete. | warning | PT10M |
| KubeJobFailed | `kube_job_failed{job="kube-state-metrics"}  > 0` | PT15M | Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete. Removing failed job after investigation should clear this alert. | warning | PT10M |
| KubeHpaReplicasMismatch | `(kube_horizontalpodautoscaler_status_desired_replicas{job="kube-state-metrics"}\n  !=\nkube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"})\n  and\n(kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}\n  >\nkube_horizontalpodautoscaler_spec_min_replicas{job="kube-state-metrics"})\n  and\n(kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}\n  <\nkube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"})\n  and\nchanges(kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}[15m]) == 0` | PT15M | HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has not matched the desired number of replicas for longer than 15 minutes. | warning | PT10M |
| KubeHpaMaxedOut| `kube_horizontalpodautoscaler_status_current_replicas{job="kube-state-metrics"}\n  ==\nkube_horizontalpodautoscaler_spec_max_replicas{job="kube-state-metrics"}` | PT15M | HPA {{ $labels.namespace }}/{{ $labels.horizontalpodautoscaler  }} has been running at max replicas for longer than 15 minutes. | warning  | PT10M |


## kubernetes-resources

Here is the Bicep Prometheus alerts documentation in a markdown table format:

| Alert | Expression | For | Description | Severity | Time to Resolve |
| --- | --- | --- | --- | --- | --- |
| KubeCPUOvercommit     | `sum(namespace_cpu:kube_pod_container_resource_requests:sum{}) - (sum(kube_node_status_allocatable{resource="cpu", job="kube-state-metrics"}) - max(kube_node_status_allocatable{resource="cpu", job="kube-state-metrics"})) > 0\nand\n(sum(kube_node_status_allocatable{resource="cpu", job="kube-state-metrics"}) - max(kube_node_status_allocatable{resource="cpu", job="kube-state-metrics"})) > 0\n` | PT10M | Cluster has overcommitted CPU resource requests for Pods by {{ $value }} CPU shares and cannot tolerate node failure. | warning | PT10M |
| KubeMemoryOvercommit  | `sum(namespace_memory:kube_pod_container_resource_requests:sum{}) - (sum(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"}) - max(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"})) > 0\nand\n(sum(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"}) - max(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"})) > 0\n` | PT10M | Cluster has overcommitted memory resource requests for Pods by {{ $value \| humanize }} bytes and cannot tolerate node failure. | warning  | PT10M |
| KubeCPUQuotaOvercommit | `sum(min without(resource) (kube_resourcequota{job="kube-state-metrics", type="hard", resource=~"(cpu\|requests.cpu)"}))\n  /\nsum(kube_node_status_allocatable{resource="cpu", job="kube-state-metrics"})\n  > 1.5\n` | PT5M | Cluster has overcommitted CPU resource requests for Namespaces. | warning  | PT10M |
| KubeMemoryQuotaOvercommit | `sum(min without(resource) (kube_resourcequota{job="kube-state-metrics", type="hard", resource=~"(memory\|requests.memory)"}))\n  /\nsum(kube_node_status_allocatable{resource="memory", job="kube-state-metrics"})\n  > 1.5\n` | PT5M | Cluster has overcommitted memory resource requests for Namespaces. | warning | PT10M |
| KubeQuotaAlmostFull | `kube_resourcequota{job="kube-state-metrics", type="used"}\n  / ignoring(instance, job, type)\n(kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)\n  > 0.9 < 1\n` | PT15M | Namespace {{ $labels.namespace }} is using {{ $value \| humanizePercentage }} of its {{ $labels.resource }} quota. | info | PT10M |
| KubeQuotaFullyUsed | `kube_resourcequota{job="kube-state-metrics", type="used"}\n  / ignoring(instance, job, type)\n(kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)\n  == 1\n` | PT15M | Namespace {{ $labels.namespace }} is using {{ $value \| humanizePercentage }} of its {{ $labels.resource }} quota. | info | PT10M  |
| KubeQuotaExceeded | `kube_resourcequota{job="kube-state-metrics", type="used"}\n  / ignoring(instance, job, type)\n(kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)\n  > 1\n` | PT15M | Namespace {{ $labels.namespace }} is using {{ $value \| humanizePercentage }} of its {{ $labels.resource }} quota. | warning  | PT10M |
| CPUThrottlingHigh | `sum(increase(container_cpu_cfs_throttled_periods_total{container!="", }[5m])) by (container, pod, namespace)\n  /\nsum(increase(container_cpu_cfs_periods_total{}[5m])) by (container, pod, namespace)\n  > ( 25 / 100 )\n` | PT15M | {{ $value \| humanizePercentage }} throttling of CPU in namespace {{ $labels.namespace }} for container {{ $labels.container }} in pod {{ $labels.pod }}. | info | PT10M |

